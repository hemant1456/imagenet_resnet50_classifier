{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "the class are   airplane--automobile--bird--cat--deer--dog--frog--horse--ship--truck\n",
      "\n",
      "train_dataset.data.shape=(50000, 32, 32, 3)\n",
      "test_dataset.data.shape=(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloader import cifar_10_dataloader, view_sample_images\n",
    "train_dataset, test_dataset, train_loader, test_loader = cifar_10_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.transforms.transforms.ToTensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_sample_images(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current accelerator is mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"current accelerator is {torch.accelerator.current_accelerator()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "simple_model                             [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 16, 32, 32]           --\n",
       "│    └─Conv2d: 2-1                       [1, 16, 32, 32]           432\n",
       "│    └─BatchNorm2d: 2-2                  [1, 16, 32, 32]           32\n",
       "│    └─ReLU: 2-3                         [1, 16, 32, 32]           --\n",
       "├─Sequential: 1-2                        [1, 16, 32, 32]           --\n",
       "│    └─Conv2d: 2-4                       [1, 16, 32, 32]           2,304\n",
       "│    └─BatchNorm2d: 2-5                  [1, 16, 32, 32]           32\n",
       "│    └─ReLU: 2-6                         [1, 16, 32, 32]           --\n",
       "├─MaxPool2d: 1-3                         [1, 16, 16, 16]           --\n",
       "├─Sequential: 1-4                        [1, 32, 16, 16]           --\n",
       "│    └─Conv2d: 2-7                       [1, 32, 16, 16]           4,608\n",
       "│    └─BatchNorm2d: 2-8                  [1, 32, 16, 16]           64\n",
       "│    └─ReLU: 2-9                         [1, 32, 16, 16]           --\n",
       "├─Sequential: 1-5                        [1, 32, 16, 16]           --\n",
       "│    └─Conv2d: 2-10                      [1, 32, 16, 16]           9,216\n",
       "│    └─BatchNorm2d: 2-11                 [1, 32, 16, 16]           64\n",
       "│    └─ReLU: 2-12                        [1, 32, 16, 16]           --\n",
       "├─MaxPool2d: 1-6                         [1, 32, 8, 8]             --\n",
       "├─Sequential: 1-7                        [1, 64, 8, 8]             --\n",
       "│    └─Conv2d: 2-13                      [1, 64, 8, 8]             18,432\n",
       "│    └─BatchNorm2d: 2-14                 [1, 64, 8, 8]             128\n",
       "│    └─ReLU: 2-15                        [1, 64, 8, 8]             --\n",
       "├─Sequential: 1-8                        [1, 64, 4, 4]             --\n",
       "│    └─Conv2d: 2-16                      [1, 64, 4, 4]             36,864\n",
       "│    └─BatchNorm2d: 2-17                 [1, 64, 4, 4]             128\n",
       "│    └─ReLU: 2-18                        [1, 64, 4, 4]             --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [1, 64, 1, 1]             --\n",
       "├─Conv2d: 1-10                           [1, 10, 1, 1]             640\n",
       "==========================================================================================\n",
       "Total params: 72,944\n",
       "Trainable params: 72,944\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 8.11\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.87\n",
       "Params size (MB): 0.29\n",
       "Estimated Total Size (MB): 1.17\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.cifar10_simple_model import simple_model\n",
    "from torchinfo import summary\n",
    "\n",
    "model = simple_model().to(device)\n",
    "\n",
    "summary(model, input_data=torch.randn(1,3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch = 1: 100%|██████████| 3125/3125 [01:10<00:00, 44.45it/s, train_loss=1.87, train_accuracy=0.292]\n",
      "epoch = 1: 100%|██████████| 625/625 [00:03<00:00, 166.12it/s, test_accuracy=tensor(0.3887)]\n",
      "epoch = 2: 100%|██████████| 3125/3125 [01:09<00:00, 45.13it/s, train_loss=1.55, train_accuracy=0.405]\n",
      "epoch = 2: 100%|██████████| 625/625 [00:04<00:00, 151.61it/s, test_accuracy=tensor(0.4553)]\n",
      "epoch = 3: 100%|██████████| 3125/3125 [01:10<00:00, 44.15it/s, train_loss=1.57, train_accuracy=0.458] \n",
      "epoch = 3: 100%|██████████| 625/625 [00:04<00:00, 147.90it/s, test_accuracy=tensor(0.4753)]\n",
      "epoch = 4:  49%|████▉     | 1542/3125 [00:30<00:26, 59.44it/s, train_loss=1.48, train_accuracy=0.485] "
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters())\n",
    "epochs = 4\n",
    "for epoch in range(epochs):\n",
    "    correct,total = 0, 0\n",
    "    model.train()\n",
    "    train_pbar = tqdm(train_loader,desc=f\"epoch = {epoch+1}\")\n",
    "    for images, labels in train_pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        _, prediction = torch.max(output,1)\n",
    "        loss= criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct+= sum(prediction==labels).item()\n",
    "        total+= len(labels)\n",
    "        train_pbar.set_postfix({\n",
    "            'train_loss': loss.item(),\n",
    "            'train_accuracy': correct/total\n",
    "        })\n",
    "\n",
    "    correct, total = 0, 0 \n",
    "    model.eval()\n",
    "    test_pbar = tqdm(test_loader,desc=f\"epoch = {epoch+1}\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            _, prediction = torch.max(output,1)\n",
    "            loss= criterion(output, labels)\n",
    "            correct+= sum(prediction==labels)\n",
    "            total+= len(labels)\n",
    "            test_pbar.set_postfix({\n",
    "            'test_accuracy': correct/total\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
